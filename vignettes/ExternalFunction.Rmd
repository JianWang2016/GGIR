---
title: "Embedding external functions in GGIR"
author: "Vincent van Hees"
date: "December 5 2019"
output:
  pdf_document:
    toc: true
    toc_depth: 3
    number_sections: true

vignette: >
  %\VignetteIndexEntry{Accelerometer data processing with GGIR}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

**Challenge**
If you are developing an algorithm for processing raw accelerometer data you may be interested to pilot it on a large dataset. For example, the algorithm could be classification algorithm. However, to do it well you would have to build code to read, clean and aggregate the data in an efficient way. Developing such code takes a lot of time.

**Solution offered by GGIR**
GGIR allows you to integrate external functions that are written in R or Python. This gives you the advantage that you can use the tested data handling infrastructure GGIR offers and plugin your own algorithm. This vignette explains how to do this.

**How it works**
GGIR internally loads the raw accelerometer data in memory blocks of about 24 hours. When the raw acceleration data is in memory and corrected for calibration error GGIR applies it own default algorithms to it as well as the external function provided by you. The only requirement is that this external function takes a three-column matrix with the acceleration data and an optional parameters argument as input and provides a time series as output.

# Example with external R function

In this example we will apply the function counts() from R package activityCounts to the raw data.

## Write external function

Create **calculateCounts.R** and insert:

```{R,eval=FALSE}
calculateCounts = function(data=c(), parameters=c()) {
  # data: 3 column matrix with acc data
  # parameters: the sample rate of data
  library("activityCounts")
  mycounts = counts(data=data, hertz=parameters, 
                    x_axis=1, y_axis=2, z_axis=3,
                    start_time = Sys.time())
  mycounts = mycounts[,2:4] #Note: do not provide timestamps to GGIR
  return(mycounts)
}
```

## Provide external function to GGIR

Create a new R script for running the GGIR analysis, e.g. myscript.R, and insert:

```{R,eval=FALSE}
myfun =  list(FUN="~/calculateCounts.R",
              parameters= 30,
              expected_sample_rate= 30,
              expected_unit="g",
              colnames = c("countsX","countsY","countsZ"),
              minlength = 1,
              outputres = 1,
              outputtype="numeric",
              aggfunction = sum)
```

The above code creates a list object `myfun` which is expected to come with the following content:

- `FUN` A character string specifying the location of the external function you want to apply.
- `parameters` The parameters used by the function, which can be stored in any format (vector, matrix, list, data.frame). The user should make sure that the external function can handle this object.
- `expected_unit` Expected unit of the acceleration by external function: "mg", "g" or "ms2".
- `colnames` Character vector with the names of the columns produced by the external function.
- `minlength` The minimum length (seconds) of data needed, typically the window per which output is provided.
- `outputres` The resolution (seconds) of the output produced by the external function. Note, that this needs to be equal to or a multitude of the short epoch size of the g.part1 output (5 seconds) or the short epoch size should be a multitude of this resolution. In this way GGIR can aggregate or repeate the external function output to be used inside GGIR.
- `outputtype` Type of external function output. Set to "numeric" if data is stored in numbers (any format).
- `aggfunction` The function used for aggregation if the data needs to be aggregated to match the short epoch size of the g.part1 output (5 seconds).

Next, add a call to GGIR function g.shell.GGIR where `myfun` is provided as argument:

```{R,eval=FALSE}
library(GGIR)
g.shell.GGIR(datadir="~/myaccelerometerdata",
             outputdir="~/myresults",
             myfun=myfun)
```

Please see to GGIR [vignette](https://cran.r-project.org/package=GGIR/vignettes/GGIR.html) on what other arguments can be provided to the g.shell.GGIR.

\pagebreak

# Example with external Python function

In this example we will use external Python code to estimate the dominant signal frequency per acceleration axis. Needless to say that this can also be done within R, but it only as an example of how to embed Python code.

## Write external function

Create **dominant_frequency.py** with the Python code to estimate the dominant frequency:

```{Python,eval=FALSE}
import numpy

def dominant_frequency(x, sf):
  # x: vector with data values
  # sf: sample frequency
  fourier = numpy.fft.fft(x)
  frequencies = numpy.fft.fftfreq(len(x), 1/sf)
  magnitudes = abs(fourier[numpy.where(frequencies > 0)])
  peak_frequency = frequencies[numpy.argmax(magnitudes)]
  return peak_frequency
```

Create **dominant_frequency.R** that calls the python function:

```{R,eval=FALSE}
dominant_frequency = function(data=c(), parameters=c()) {
  # data: 3 column matrix with acc data
  # parameters: the sample rate of data
  source_python("dominant_frequency.py")
  sf=parameters
  N = nrow(data)
  ws = 5 # windowsize
  data = data.frame(t= floor(seq(0,(N-1)/sf,by=1/sf)/ws),
                    x=data[,1], y=data[,2], z=data[,3])
  df = aggregate(data, by = list(data$t), 
                 FUN=function(x) {return(dominant_frequency(x,sf))})
  df = df[,-c(1:2)]
  return(df)
}
}
```

## Provide external function to GGIR

Create a new R script, e.g. myscript.R, and insert the following components.

A specification of the Python environment to use, this can also be a conda environment or docker container (see documentation R package [reticulate](https://rstudio.github.io/reticulate/) for details on that). Make sure that that this Python environment has all the required dependencies.

```{R,eval=FALSE}
  library("reticulate")
  use_virtualenv("~/venv", required = TRUE) # Local Python environment

```

Specify a `myfun` object

```{R,eval=FALSE}
myfun =  list(FUN=exampleExtFunction,
              parameters= 30,
              expected_sample_rate= 30,
              expected_unit="g",
              colnames = c("domfreqX", "domfreqY", "domfreqZ"),
              minlength = 5,
              outputres = 5,
              outputtype="numeric",
              aggfunction = median)
```

Add a call to GGIR function g.shell.GGIR where `myfun` is provided as argument as we did before for the R example:

```{R,eval=FALSE}
library(GGIR)
g.shell.GGIR(datadir="~/myaccelerometerdata",
             outputdir="~/myresults",
             myfun=myfun)
```


# Integration in GGIR output

## Part 1
The external function output is included in the time series produced by function GGIR function g.part1 and stored in an RData-file in /output_nameofstudy/meta/basic.
The resolution of these output in GGIR is set by g.shell.GGIR argument `windowsizes`, which is c(5,900,3600) by default. Here, the first element (5) specifics the short epoch size in seconds.
If the output of the external function is less then this resolution it will be aggregated with the function as specificied by aggfunction in the `myfun` object. In the count example we used the sum for this and for the dominant frequency example we used the median.

## Part 2
Next, in part2 GGIR aims to detect non-wear periods and imputes those. The impute time series can be found in the part 2 milestone data in folder: /output_nameofstudy/meta/ms2.out. If you want these to be directly stored in a csv file then set argument `epochvalues2csv = TRUE`. Additionally, csv reports are created where the output is aggregated per day and per recording.